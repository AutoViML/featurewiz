{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cae2b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291487a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow>= 2.5 not installed in machine. Please install and try again. \n",
      "Imported lazytransform v1.10. \n",
      "\n",
      "Imported featurewiz 0.4.9. Use the following syntax:\n",
      "    >>> wiz = FeatureWiz(feature_engg = '', nrows=None, transform_target=True, scalers=\"std\",\n",
      "        \t\tcategory_encoders=\"auto\", add_missing=False, verbose=0)\n",
      "    >>> X_train_selected, y_train = wiz.fit_transform(X_train, y_train)\n",
      "    >>> X_test_selected = wiz.transform(X_test)\n",
      "    >>> selected_features = wiz.features\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from featurewiz import LazyTransformer, SuloRegressor, SuloClassifier\n",
    "from featurewiz import FeatureWiz, cross_val_model_predictions\n",
    "from featurewiz import print_regression_metrics, print_classification_metrics,print_sulo_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad4d777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affair_multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "\n",
       "   occupation_husb  affair_multiclass  \n",
       "0              5.0                  0  \n",
       "1              4.0                  3  \n",
       "2              5.0                  1  \n",
       "3              5.0                  0  \n",
       "4              4.0                  4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = 'c:/users/ram/documents/ram/data_sets/kaggle/diabetes.csv'\n",
    "datapath = '../Ram/Data_Sets/'\n",
    "filename = 'winequality.csv'\n",
    "filename = 'affairs.csv'\n",
    "trainfile = datapath+filename\n",
    "sep = ','\n",
    "dft = pd.read_csv(trainfile,sep=sep)\n",
    "dft.drop(['affairs','affair'],axis=1, inplace=True)\n",
    "print(dft.shape)\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551ba04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import LazyTransformer, get_class_distribution, get_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eab3006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'affair_multiclass'\n",
    "#target = 'quality'\n",
    "modeltype = 'Multi_Classification'\n",
    "preds = [x for x in list(dft) if x not in target]\n",
    "dft[target].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684dade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5092, 8) (1274, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from featurewiz import FE_kmeans_resampler\n",
    "if modeltype == 'Regression':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dft[preds], dft[target], test_size=0.20, random_state=1,)\n",
    "    X_train_over, y_train_over = FE_kmeans_resampler(X_train, y_train, target, smote='',verbose=0)\n",
    "    print(X_train_over.shape, X_test.shape)\n",
    "    #train, test = pd.concat([X_train_over, pd.Series(y_train_over,name=target)], axis=1), pd.concat([X_test, y_test], axis=1)\n",
    "    train, test = train_test_split(dft, test_size=0.20, random_state=42)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dft[preds], dft[target], test_size=0.20, \n",
    "                                                    stratify=dft[target],\n",
    "                                                    random_state=42)\n",
    "    train, test = train_test_split(dft, test_size=0.20, random_state=42,\n",
    "                                                    stratify=dft[target]\n",
    "                                                   )\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5595334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dae_dicto = {\n",
    "    'noise_factor': 0.2,\n",
    "    'encoding_dim': 10,\n",
    "    'epochs': 100, \n",
    "    'batch_size': 32,\n",
    "    'simple_architecture': None\n",
    "         }\n",
    "vae_dicto = {\n",
    "    'intermediate_dim': 32,\n",
    "    'latent_dim': 4,\n",
    "    'epochs': 100, \n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001\n",
    "         }\n",
    "gan_dicto = {\n",
    "    'gan_model':None,\n",
    "    'input_dim': 100,\n",
    "    'embedding_dim': 100, \n",
    "    'epochs': 100, \n",
    "    'num_synthetic_samples': 400,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a40921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz is given 0.9 as correlation limit...\n",
      "    Warning: Too many features will be generated since feature engg specified\n",
      "    final list of feature engineering given: ['vae_add']\n",
      "    final list of category encoders given: ['onehot', 'label']\n",
      "AutoEncoder VariationalAutoEncoder(batch_size=32, epochs=100, intermediate_dim=32)\n",
      "    AE options: dict_items([('intermediate_dim', 32), ('latent_dim', 4), ('epochs', 100), ('batch_size', 32), ('learning_rate', 0.001)])\n",
      "    final list of scalers given: [minmax]\n"
     ]
    }
   ],
   "source": [
    "scaler = FeatureWiz(feature_engg = 'vae_add', nrows=None, transform_target=True, scalers=\"MinMax\",\n",
    "        \t\tcategory_encoders=\"auto\", add_missing=False, verbose=0, imbalanced=False,\n",
    "                   ae_options=vae_dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc6dc4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded input data. Shape = (5092, 8)\n",
      "#### Starting featurewiz transform for train data ####\n",
      "No groupby features created since no groupby feature engg specified\n",
      "No interactions created for categorical vars since no interactions feature engg specified\n",
      "    Single_Label Multi_Classification problem \n",
      "Shape of dataset: (5092, 8). Now we classify variables into different types...\n",
      "Time taken to define data pipeline = 1 second(s)\n",
      "No model input given...\n",
      "Lazy Transformer Pipeline created...\n",
      "    transformed target from object type to numeric\n",
      "    Time taken to fit dataset = 1 second(s)\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (5092, 8)\n",
      "Using Variational Auto Encoder to extract features...\n",
      "Epoch 1/100\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.9101 - val_loss: 0.7354 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.6526 - val_loss: 0.6324 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5947 - val_loss: 0.6024 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5710 - val_loss: 0.5818 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5734 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 0.5662 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.5654 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5521 - val_loss: 0.5630 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5507 - val_loss: 0.5610 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 0.5611 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.5593 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 0.5598 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5488 - val_loss: 0.5601 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.5591 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.5592 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5453 - val_loss: 0.5591 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.5588 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.5580 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.5563 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 0.5578 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.5571 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5565 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.5575 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.5564 - lr: 0.0010\n",
      "Epoch 00024: early stopping\n",
      "Fitting and transforming an Auto Encoder for dataset...\n",
      "Shape of transformed data due to auto encoder = (5092, 12)\n",
      "    Single_Label Multi_Classification problem \n",
      "Starting SULOV with 12 features...\n",
      "    there are no null values in dataset...\n",
      "    there are no null values in target column...\n",
      "Completed SULOV. 11 features selected\n",
      "Performing recursive XGBoost feature selection from 11 features...\n",
      "    time taken to run entire featurewiz = 25 second(s)\n",
      "Recursive XGBoost selected 5 features...\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess your dataset\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "# Scale the data\n",
    "#scaler = MinMaxScaler()\n",
    "encoded_X_train, encoded_y_train = scaler.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b6987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Starting featurewiz transform for test data ####\n",
      "Loaded input data. Shape = (1274, 8)\n",
      "    Beware! feature_engg will add 100s, if not 1000s of additional features to your dataset!\n",
      "#### Starting lazytransform for test data ####\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (1274, 8)\n",
      "Shape of transformed data due to auto encoder = (1274, 12)\n",
      "Returning dataframe with 5 features \n"
     ]
    }
   ],
   "source": [
    "### Since you modified y_train to numeric, you must do same for y_test\n",
    "encoded_X_test = scaler.transform(X_test)\n",
    "y_test = scaler.lazy.yformer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa3d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bal accu 15%\n",
      "ROC AUC = 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1050\n",
      "           1       0.14      0.05      0.07        86\n",
      "           2       0.15      0.04      0.07        48\n",
      "           3       0.05      0.04      0.04        26\n",
      "           4       0.00      0.00      0.00        35\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79      1274\n",
      "   macro avg       0.17      0.15      0.15      1274\n",
      "weighted avg       0.70      0.79      0.74      1274\n",
      "\n",
      "final average balanced accuracy score = 0.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Train an SVM classifier on the encoded features\n",
    "# svm_classifier = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', probability=True)\n",
    "# Use the Random Forest Classifier with the corrected class weights which seems to work very well\n",
    "### get_class_weights has lower ROC_AUC but get_class_distribution has higher F1 scores\n",
    "class_weights_dict_corrected = get_class_distribution(encoded_y_train)\n",
    "class_weights_dict_corrected = dict(zip(class_weights_dict_corrected.keys(),np.int8(np.reciprocal(list(class_weights_dict_corrected\n",
    "                                                        .values())/max(list(class_weights_dict_corrected.values()))))))\n",
    "svm_classifier = RandomForestClassifier(n_estimators=200, \n",
    "                                        #class_weight=class_weights_dict_corrected, \n",
    "                                        random_state=42)\n",
    "\n",
    "svm_classifier.fit(encoded_X_train, encoded_y_train)\n",
    "\n",
    "# Make predictions on the test set using the SVM classifier\n",
    "svm_predictions = svm_classifier.predict(encoded_X_test)\n",
    "svm_probas = svm_classifier.predict_proba(encoded_X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = balanced_accuracy_score(y_test, svm_predictions)\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, y_pred)\n",
    "else:\n",
    "    print_classification_metrics(y_test, svm_predictions, svm_probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db90be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 12, 2: 21, 3: 40, 4: 30, 5: 58, 6: 58}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_dict_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbc4fe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz is given 0.9 as correlation limit...\n",
      "    Skipping feature engineering since no feature_engg input...\n",
      "    final list of category encoders given: ['label', 'label']\n",
      "    final list of scalers given: []\n",
      "Loaded input data. Shape = (5092, 8)\n",
      "#### Starting featurewiz transform for train data ####\n",
      "    Single_Label Multi_Classification problem \n",
      "Shape of dataset: (5092, 8). Now we classify variables into different types...\n",
      "Time taken to define data pipeline = 1 second(s)\n",
      "No model input given...\n",
      "Lazy Transformer Pipeline created...\n",
      "    transformed target from object type to numeric\n",
      "    Time taken to fit dataset = 1 second(s)\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (5092, 8)\n",
      "    Single_Label Multi_Classification problem \n",
      "Starting SULOV with 8 features...\n",
      "    Selecting all (8) variables since none of numeric vars are highly correlated...\n",
      "Performing recursive XGBoost feature selection from 8 features...\n",
      "    time taken to run entire featurewiz = 5 second(s)\n",
      "Recursive XGBoost selected 7 features...\n"
     ]
    }
   ],
   "source": [
    "fwiz = FeatureWiz(corr_limit=0.90, feature_engg='', category_encoders='', transform_target=True,\n",
    "                 dask_xgboost_flag=False, nrows=None, verbose=0) \n",
    "X_train_selected, y_train = fwiz.fit_transform(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a597eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Starting featurewiz transform for test data ####\n",
      "Loaded input data. Shape = (1274, 8)\n",
      "#### Starting lazytransform for test data ####\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (1274, 8)\n",
      "Returning dataframe with 7 features \n"
     ]
    }
   ],
   "source": [
    "X_test_selected = fwiz.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088977b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bal accu 16%\n",
      "ROC AUC = 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1050\n",
      "           1       0.14      0.05      0.07        86\n",
      "           2       0.15      0.04      0.07        48\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.27      0.09      0.13        35\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79      1274\n",
      "   macro avg       0.20      0.16      0.16      1274\n",
      "weighted avg       0.71      0.79      0.74      1274\n",
      "\n",
      "final average balanced accuracy score = 0.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Correctly computing class weights for the classes present in the training set\n",
    "class_weights_dict_corrected = get_class_distribution(y_train)\n",
    "class_weights_dict_corrected = dict(zip(class_weights_dict_corrected.keys(),np.int8(np.reciprocal(list(class_weights_dict_corrected\n",
    "                                                        .values())/max(list(class_weights_dict_corrected.values()))))))\n",
    "\n",
    "# Updating the Random Forest Classifier with the corrected class weights\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, \n",
    "                                       #class_weight=class_weights_dict_corrected,\n",
    "                                       random_state=42)\n",
    "\n",
    "# Fitting the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the classifier\n",
    "y_probas = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, y_pred)\n",
    "else:\n",
    "    print_classification_metrics(y_test, y_pred, y_probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8448a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 58, 1: 4, 2: 2, 3: 1, 4: 1, 5: 1, 6: 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_dict_corrected = dict(zip(class_weights_dict_corrected.keys(),np.int8(np.reciprocal(list(class_weights_dict_corrected\n",
    "                                                        .values())/max(list(class_weights_dict_corrected.values()))))))\n",
    "class_weights_dict_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ff2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04138c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
