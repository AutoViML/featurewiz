{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974b4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.options.display.max_columns=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f295cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported lazytransform v1.11. \n",
      "\n",
      "Imported featurewiz 0.5.2. Use the following syntax:\n",
      "    >>> wiz = FeatureWiz(feature_engg = '', nrows=None, transform_target=True, scalers=\"std\",\n",
      "        \t\tcategory_encoders=\"auto\", add_missing=False, verbose=0. imbalanced=False,\n",
      "        \t\tae_options={})\n",
      "    >>> X_train_selected, y_train = wiz.fit_transform(X_train, y_train)\n",
      "    >>> X_test_selected = wiz.transform(X_test)\n",
      "    >>> selected_features = wiz.features\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from featurewiz import LazyTransformer, SuloRegressor, SuloClassifier\n",
    "from featurewiz import FeatureWiz, cross_val_model_predictions\n",
    "from featurewiz import print_regression_metrics, print_classification_metrics,print_sulo_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae6165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affair_multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "\n",
       "   occupation_husb  affair_multiclass  \n",
       "0              5.0                  0  \n",
       "1              4.0                  3  \n",
       "2              5.0                  1  \n",
       "3              5.0                  0  \n",
       "4              4.0                  4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = 'c:/users/ram/documents/ram/data_sets/kaggle/diabetes.csv'\n",
    "datapath = '../Ram/Data_Sets/'\n",
    "filename = 'winequality.csv'\n",
    "#filename = 'sales.csv'\n",
    "filename = 'affairs.csv'\n",
    "trainfile = datapath+filename\n",
    "sep = ','\n",
    "dft = pd.read_csv(trainfile,sep=sep)\n",
    "dft.drop(['affair','affairs'],axis=1, inplace=True)\n",
    "print(dft.shape)\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c68704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'affair_multiclass'\n",
    "preds = [x for x in list(dft) if x not in [target]]\n",
    "modeltype = 'Multi_Classification'\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0959c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import StackingClassifier_Multi, get_class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55befcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5092, 8) (1274, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from featurewiz import FE_kmeans_resampler\n",
    "if modeltype == 'Regression':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dft[preds], dft[target], test_size=0.20, random_state=1,)\n",
    "    #X_train_over, y_train_over = FE_kmeans_resampler(X_train, y_train, target, smote='',verbose=0)\n",
    "    #print(X_train_over.shape, X_test.shape)\n",
    "    #train, test = pd.concat([X_train_over, pd.Series(y_train_over,name=target)], axis=1), pd.concat([X_test, y_test], axis=1)\n",
    "    train, test = train_test_split(dft, test_size=0.20, random_state=42)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dft[preds], dft[target], test_size=0.20, \n",
    "                                                    stratify=dft[target],\n",
    "                                                    random_state=42)\n",
    "    train, test = train_test_split(dft, test_size=0.20, random_state=42,\n",
    "                                                    stratify=dft[target]\n",
    "                                                   )\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab07b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_target = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1bb366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz is given 0.8 as correlation limit...\n",
      "    Warning: Too many features will be generated since feature engg specified\n",
      "    final list of feature engineering given: ['dae_add']\n",
      "    final list of category encoders given: ['onehot', 'label']\n",
      "Since Auto Encoders are selected for feature extraction,\n",
      "    Recursive XGBoost is skipped...\n",
      "DenoisingAutoEncoder()\n",
      "    AE dictionary given: dict_items([])\n",
      "    final list of scalers given: [minmax]\n",
      "Loaded input data. Shape = (5092, 8)\n",
      "Performing hyper param selection...\n",
      "    defining a pipeline with MinMaxScaler and DAE\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 2s 6ms/step - loss: 0.2109 - mse: 0.1736 - val_loss: 0.1019 - val_mse: 0.0712 - lr: 0.0100\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0897 - mse: 0.0653 - val_loss: 0.0882 - val_mse: 0.0696 - lr: 0.0100\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0691 - mse: 0.0552 - val_loss: 0.0778 - val_mse: 0.0682 - lr: 0.0100\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0586 - mse: 0.0517 - val_loss: 0.0717 - val_mse: 0.0668 - lr: 0.0100\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0540 - mse: 0.0503 - val_loss: 0.0615 - val_mse: 0.0589 - lr: 0.0100\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0519 - mse: 0.0498 - val_loss: 0.0519 - val_mse: 0.0501 - lr: 0.0100\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0508 - mse: 0.0494 - val_loss: 0.0515 - val_mse: 0.0503 - lr: 0.0100\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0505 - mse: 0.0494 - val_loss: 0.0486 - val_mse: 0.0476 - lr: 0.0100\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0504 - mse: 0.0494 - val_loss: 0.0476 - val_mse: 0.0466 - lr: 0.0100\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0501 - mse: 0.0490 - val_loss: 0.0478 - val_mse: 0.0467 - lr: 0.0100\n",
      "    time taken for DAE hyper param selection = 150 seconds\n",
      "{'feature_extractor__batch_size': 16, 'feature_extractor__epochs': 10, 'feature_extractor__noise_type': 'gaussian', 'feature_extractor__num_hidden_layers': 2}\n",
      "    selecting 8 numeric features for further processing...\n",
      "#### Starting featurewiz transform for train data ####\n",
      "No groupby features created since no groupby feature engg specified\n",
      "No interactions created for categorical vars since no interactions feature engg specified\n",
      "    Single_Label Multi_Classification problem \n",
      "Shape of dataset: (5092, 8). Now we classify variables into different types...\n",
      "    Returning dictionary for variable types with following keys:\n",
      "                        continuous_vars = 8, int_vars = 0, \n",
      "                        discrete_string_vars = 0, nlp_vars = 0,\n",
      "                        date_vars = 0, time_deltas = 0,\n",
      "                        categorical_vars = 0, date_zones = 0\n",
      "    no date time variables detected in this dataset\n",
      "    Beware! onehot encoding can create hundreds if not 1000s of variables...\n",
      "label encoder selected for transforming all categorical variables\n",
      "Using OneHotEncoder() and My_LabelEncoder() as encoders\n",
      "Caution: ### When you have categorical or date-time vars in data, scaling may not be helpful. ##\n",
      "Check the pipeline creation statement for errors (if any):\n",
      "\tmake_column_transformer((imp, intvars),(imp, floatvars),    remainder=remainder)\n",
      "    no other vars left in dataset to transform...\n",
      "Time taken to define data pipeline = 1 second(s)\n",
      "No model input given...\n",
      "Lazy Transformer Pipeline created...\n",
      "    transformed target from object type to numeric\n",
      "    Time taken to fit dataset = 1 second(s)\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (5092, 8)\n",
      "Epoch 1/100\n",
      "128/128 [==============================] - 3s 6ms/step - loss: 0.2206 - mse: 0.1835 - val_loss: 0.1000 - val_mse: 0.0678 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0901 - mse: 0.0626 - val_loss: 0.0777 - val_mse: 0.0548 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0708 - mse: 0.0520 - val_loss: 0.0712 - val_mse: 0.0566 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0608 - mse: 0.0490 - val_loss: 0.0652 - val_mse: 0.0558 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0545 - mse: 0.0470 - val_loss: 0.0497 - val_mse: 0.0438 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0507 - mse: 0.0460 - val_loss: 0.0507 - val_mse: 0.0470 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0487 - mse: 0.0458 - val_loss: 0.0439 - val_mse: 0.0414 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0474 - mse: 0.0453 - val_loss: 0.0436 - val_mse: 0.0417 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0462 - mse: 0.0446 - val_loss: 0.0494 - val_mse: 0.0479 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0457 - mse: 0.0443 - val_loss: 0.0428 - val_mse: 0.0414 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0459 - mse: 0.0444 - val_loss: 0.0415 - val_mse: 0.0400 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0444 - val_loss: 0.0421 - val_mse: 0.0406 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0441 - val_loss: 0.0416 - val_mse: 0.0400 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0458 - mse: 0.0443 - val_loss: 0.0512 - val_mse: 0.0499 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0452 - mse: 0.0437 - val_loss: 0.0473 - val_mse: 0.0459 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0433 - val_loss: 0.0458 - val_mse: 0.0442 - lr: 0.0100\n",
      "Fitting and transforming an Auto Encoder for dataset...\n",
      "Shape of transformed data due to auto encoder = (5092, 10)\n",
      "    Single_Label Multi_Classification problem \n",
      "    time taken to run entire featurewiz = 10 second(s)\n",
      "Recursive XGBoost selected 10 features...\n"
     ]
    }
   ],
   "source": [
    "fwiz = FeatureWiz(corr_limit=0.80, feature_engg='dae_add', category_encoders='auto', \n",
    "                 dask_xgboost_flag=False, nrows=None, verbose=2, skip_sulov=True,\n",
    "                 skip_xgboost=False, transform_target=transform_target) \n",
    "X_train_selected, y_train = fwiz.fit_transform(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe4a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5092, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>ae_feature_1</th>\n",
       "      <th>ae_feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566451</td>\n",
       "      <td>0.379408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.068312</td>\n",
       "      <td>0.870748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.749694</td>\n",
       "      <td>0.414009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.152196</td>\n",
       "      <td>0.583464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate_marriage       age  yrs_married  children  religious      educ  \\\n",
       "389            0.75  1.000000     1.000000  0.181818   0.666667  0.272727   \n",
       "1810           0.00  1.000000     1.000000  0.545455   0.666667  1.000000   \n",
       "841            0.75  0.000000     0.088889  0.181818   0.000000  0.272727   \n",
       "2089           0.75  0.183673     0.088889  0.000000   0.666667  0.636364   \n",
       "1971           0.75  0.387755     0.244444  0.181818   0.666667  0.272727   \n",
       "\n",
       "      occupation  occupation_husb  ae_feature_1  ae_feature_2  \n",
       "389          0.4              0.4      0.566451      0.379408  \n",
       "1810         0.6              0.6      0.000000      0.035628  \n",
       "841          0.4              0.2      3.068312      0.870748  \n",
       "2089         0.6              1.0      2.749694      0.414009  \n",
       "1971         0.4              0.6      2.152196      0.583464  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_selected.shape)\n",
    "X_train_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "925f933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Starting featurewiz transform for test data ####\n",
      "Loaded input data. Shape = (1274, 8)\n",
      "    Beware! feature_engg will add 100s, if not 1000s of additional features to your dataset!\n",
      "#### Starting lazytransform for test data ####\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (1274, 8)\n",
      "Shape of transformed data due to auto encoder = (1274, 10)\n",
      "Returning dataframe with 10 features \n"
     ]
    }
   ],
   "source": [
    "X_test_selected = fwiz.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19e894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transform_target:\n",
    "    y_test = fwiz.lazy.yformer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59814220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import IterativeBinaryClassifier, IterativeDoubleClassifier_XGB\n",
    "from featurewiz import IterativeDoubleClassifier, get_class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b625e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz.blagging import BlaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652446cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bal accu 16%\n",
      "ROC AUC = 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1050\n",
      "           1       0.11      0.03      0.05        86\n",
      "           2       0.17      0.04      0.07        48\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.13      0.06      0.08        35\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79      1274\n",
      "   macro avg       0.18      0.16      0.16      1274\n",
      "weighted avg       0.70      0.79      0.74      1274\n",
      "\n",
      "final average balanced accuracy score = 0.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Updating the Random Forest Classifier with the corrected class weights\n",
    "if modeltype == 'Regression':\n",
    "    rf_classifier = RandomForestRegressor(random_state=42)\n",
    "else:\n",
    "    # Correctly computing class weights for the classes present in the training set\n",
    "    class_weights_dict_corrected = get_class_distribution(y_train)\n",
    "    #rf_classifier = RandomForestClassifier(class_weight=class_weights_dict_corrected, random_state=42)\n",
    "    rf_classifier =  IterativeDoubleClassifier(\n",
    "                                weights={1: 0.5, 2: 0.5} \n",
    "                               )\n",
    "\n",
    "\n",
    "# Fitting the classifier on the training data\n",
    "rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test_selected)\n",
    "\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, y_pred, verbose=1)\n",
    "else:\n",
    "    # Evaluating the classifier\n",
    "    y_probas = rf_classifier.predict_proba(X_test_selected)\n",
    "    print_classification_metrics(y_test, y_pred, y_probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa8c28c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c349c1096f91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'disto' is not defined"
     ]
    }
   ],
   "source": [
    "disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "\n",
    "        # start and end date for validation\n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta(days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 )\n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
    "        \n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append( m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "    'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "    'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "    'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str )}, index=[0] )\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "\n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    return pd.DataFrame( { 'Model Name': model_name,\n",
    "                            'MAE': mae,\n",
    "                            'MAPE': mape,\n",
    "                            'RMSE': rmse }, index=[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d720ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92215781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "40a4b4ae",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "# Create and train the classifier\n",
    "clf = IterativeBinaryClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74588eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Create and train the classifier\n",
    "clf = IterativeDoubleClassifier(base_classifier1=BlaggingClassifier(), \n",
    "                                base_classifier2=RandomForestClassifier(), \n",
    "                                weights={1: 0.5, 2: 0.5} \n",
    "                               )\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08387e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, predictions)\n",
    "else:\n",
    "    print_classification_metrics(y_test, predictions, probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbens.ensemble import AsymBoostClassifier, SelfPacedEnsembleClassifier, BalancedRandomForestClassifier\n",
    "from imbens.ensemble import RUSBoostClassifier, KmeansSMOTEBoostClassifier, AdaCostClassifier\n",
    "from featurewiz import BlaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9361840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_models = [AsymBoostClassifier, SelfPacedEnsembleClassifier, BalancedRandomForestClassifier,\n",
    "#              RUSBoostClassifier, KmeansSMOTEBoostClassifier, AdaCostClassifier]\n",
    "list_models = [StackingClassifier_Multi]\n",
    "#list_models = [BlaggingClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ccb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pdb\n",
    "for model in list_models:\n",
    "    start_time = time.time()\n",
    "    print('\\n',str( model).split(\".\")[-1])\n",
    "    stack = model()\n",
    "    stack.fit(X_train, y_train)\n",
    "    test_predictions = stack.predict(X_test)\n",
    "    test_probas = stack.predict_proba(X_test)\n",
    "    if modeltype == 'Regression':\n",
    "        print_regression_metrics(y_test, test_predictions)\n",
    "    else:\n",
    "        print_classification_metrics(y_test, test_predictions, test_probas, verbose=1)\n",
    "    print('Time taken = %0.0f seconds' %(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae50529",
   "metadata": {},
   "outputs": [],
   "source": [
    "disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, test_predictions)\n",
    "else:\n",
    "    print_classification_metrics(y_test, test_predictions, test_probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enco = 'catboost'\n",
    "enco = \"auto\"\n",
    "feature_engg = [\n",
    "        \"groupby\",\n",
    "        \"interactions\",\n",
    "        #\"target\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f575617",
   "metadata": {},
   "source": [
    "from featurewiz import SuloClassifier, SuloRegressor\n",
    "if modeltype == 'Regression':\n",
    "    stack = SuloRegressor()\n",
    "else:\n",
    "    stack = SuloClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fb9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if modeltype == 'Regression':\n",
    "    ### SuloRegressor works well for Regression problems ##\n",
    "    stack.fit(X_train_over, y_train_over)\n",
    "    test_predictions = model.predict(X_test)\n",
    "else:\n",
    "    ## this works well only for binary_classification problems. It is bad for Multi-class ##\n",
    "    ### SMOTE works well only for binary-class but is bad for multi-class problems - avoid!\n",
    "    test_predictions, test_probas  = cross_val_model_predictions(stack, train, test, \n",
    "                                                feature_engg=feature_engg, \n",
    "                                                feature_selection=True,\n",
    "                                                targets=[target], \n",
    "                                                modeltype=modeltype,\n",
    "                                                smote=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test, test_predictions)\n",
    "else:\n",
    "    print_classification_metrics(y_test, test_predictions, test_probas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb43110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath = '../Ram/Data_Sets/'\n",
    "datapath = '../Ram/Data_Sets/'\n",
    "filename = 'affairs.csv'\n",
    "trainfile = datapath+filename\n",
    "sep = ','\n",
    "dft = pd.read_csv(trainfile, sep=sep, nrows=10000)\n",
    "dft.drop(['affair_multiclass','affairs'],axis=1, inplace=True)\n",
    "print(dft.shape)\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8ffcd39",
   "metadata": {},
   "source": [
    "# for each in list(dft):\n",
    "    print(each, dft[each].nunique())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c66a5f8c",
   "metadata": {},
   "source": [
    "# for each in list(dft):\n",
    "    print(dft[each].map(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b097619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwiz = FeatureWiz(\n",
    "    corr_limit=0.9,\n",
    "    feature_engg=feature_engg,\n",
    "    category_encoders=enco,\n",
    "    add_missing=True,\n",
    "    nrows=None,\n",
    "    verbose=0,\n",
    "    transform_target=True,\n",
    "    scalers=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected, y_train = fwiz.fit_transform(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    ")\n",
    "\n",
    "X_test_selected  = fwiz.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This transforms y_test alone without touching X_test. Nice trick!\n",
    "if modeltype != 'Regression':\n",
    "    y_test = fwiz.lazy.yformer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7226bfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "if modeltype == 'Regression':\n",
    "    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=99)\n",
    "else:\n",
    "    model = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=99)\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f33f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazytransform import print_classification_metrics, print_regression_metrics\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test.values, y_pred)\n",
    "else:\n",
    "    y_proba = model.predict_proba(X_test_selected)\n",
    "    print_classification_metrics(y_test.values, y_pred, y_proba, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sulo_accuracy(y_test, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "if modeltype == 'Regression':\n",
    "    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=99)\n",
    "    model = XGBRegressor(n_estimators=5000, n_jobs=-1, random_state=99)\n",
    "else:\n",
    "    model = RandomForestClassifier(n_estimators=500,  n_jobs=-1, random_state=99)\n",
    "    model = XGBClassifier(n_estimators=5000, n_jobs=-1, random_state=99)\n",
    "#help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b417b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from featurewiz import cross_val_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modeltype == 'Regression':\n",
    "    print_regression_metrics(y_test.values, test_predictions,verbose=1)\n",
    "else:\n",
    "    print_classification_metrics(y_test.values, test_predictions, test_probas,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def52c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the target variable\n",
    "feats_list = {}\n",
    "feats_df = pd.DataFrame(feats_list, columns=['Method','Features', 'Num_Features','Mean RMSE']).set_index('Method')\n",
    "\n",
    "# Run featurewiz to select the best features\n",
    "fwiz = FeatureWiz(feature_engg=['interactions', 'target'], corr_limit=0.9, verbose=0)\n",
    "\n",
    "# Convert categorical columns to numeric\n",
    "dfd = pd.get_dummies(dft, drop_first=True)\n",
    "\n",
    "#### split into df and test so that we can set up a hold out set\n",
    "df, test = train_test_split(dfd, test_size=0.05, random_state=99)\n",
    "\n",
    "### select features by transforming train\n",
    "df_transformed, df_target = fwiz.fit_transform(df.drop(target, axis=1), df[target])\n",
    "features = fwiz.features\n",
    "test_transformed = test[features]\n",
    "\n",
    "# Display the selected features\n",
    "feats_df.loc['featurewiz', 'Features'] = f\"{features}\"\n",
    "feats_df.loc['featurewiz', 'Num_Features'] = len(features)\n",
    "model = RandomForestRegressor(random_state=99)\n",
    "sco = cross_val_score(model, df_transformed, df_target, cv=5, n_jobs=-1, verbose=0, scoring='neg_root_mean_squared_error')*(-1)\n",
    "feats_df.loc['featurewiz','Mean RMSE'] = sco.mean()\n",
    "model = RandomForestRegressor(random_state=99)\n",
    "model.fit(df_transformed, df_target)\n",
    "sco2 = np.sqrt(mean_squared_error(test[target], model.predict(test_transformed)))\n",
    "feats_df.loc['featurewiz','Test RMSE'] = sco2.mean()\n",
    "print(\"Time taken = %0.0f seconds\" %(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcf25a64",
   "metadata": {},
   "source": [
    "trainm, testm = FW.featurewiz(train, target,  test_data='', verbose=1, corr_limit=0.90, \n",
    "        sep=',', header=0,feature_engg='', category_encoders='',\n",
    "        dask_xgboost_flag=True, nrows=None, skip_xgboost=False\n",
    "                             )\n",
    "feats = testm.columns.tolist()\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "disto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e471e",
   "metadata": {},
   "source": [
    "# First we test the model with all features (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import simple_XGBoost_model\n",
    "y_preds = simple_XGBoost_model(train[preds], train[target], test[preds])\n",
    "ypreds0 = y_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "if modeltype != 'Regression':\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[target])\n",
    "    ypreds0 = le.inverse_transform(ypreds0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54745e6",
   "metadata": {},
   "source": [
    "# Here is the performance with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazytransform import print_regression_model_stats, print_sulo_accuracy\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_model_stats(test[target], ypreds0, verbose=1)\n",
    "else:\n",
    "    print_sulo_accuracy(test[target], ypreds0,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5dd81",
   "metadata": {},
   "source": [
    "# next we train a similar model with featurewiz features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import simple_XGBoost_model\n",
    "y_preds = simple_XGBoost_model(train[feats], train[target], test[feats])\n",
    "ypreds1 = y_preds[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "687056d5",
   "metadata": {},
   "source": [
    "from featurewiz import simple_XGBoost_model\n",
    "y_preds = simple_XGBoost_model(X_train_selected, train[target], X_test_selected)\n",
    "ypreds2 = y_preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2359364",
   "metadata": {},
   "source": [
    "# And now the results with featurewiz features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "if modeltype != 'Regression':\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[target])\n",
    "    ypreds1 = le.inverse_transform(ypreds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786acf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazytransform import print_regression_model_stats, print_sulo_accuracy\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_model_stats(test[target], ypreds1, verbose=1)\n",
    "else:\n",
    "    print_sulo_accuracy(test[target], ypreds1,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd44221",
   "metadata": {},
   "source": [
    "# Results with featurewiz selected features are better!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c8a5981",
   "metadata": {},
   "source": [
    "from lazytransform import print_regression_model_stats\n",
    "if modeltype == 'Regression':\n",
    "    print_regression_model_stats(test[target], ypreds2)\n",
    "else:\n",
    "    print_sulo_accuracy(test[target], ypreds2,verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bfeebaf",
   "metadata": {},
   "source": [
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"Color\": [\"Red\", \"Blue\", \"Green\", \"Red\", \"Green\", \"Red\", \"Blue\"],\n",
    "        \"Size\": [\"S\", \"M\", \"L\", \"XL\", \"M\", \"XL\", \"S\"],\n",
    "        \"Shape\": [\n",
    "            \"Circle\",\n",
    "            \"Square\",\n",
    "            \"Triangle\",\n",
    "            \"Circle\",\n",
    "            \"Square\",\n",
    "            \"Circle\",\n",
    "            \"Triangle\",\n",
    "        ],\n",
    "        \"Temperature\": [\"Hot\", \"Cold\", \"Hot\", \"Warm\", \"Warm\", \"Cold\", \"Hot\"],\n",
    "       \"Target\": [1, 0, 1, 1, 0, 0, 1]\n",
    "    }\n",
    ")\n",
    "X_train = data.drop(\"Target\", axis=1)\n",
    "y_train = data[\"Target\"]\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    {\n",
    "        \"Color\": [\"Red\", \"Blue\", \"Green\", \"Red\", ],\n",
    "        \"Size\": [\"S\", \"M\", \"L\", \"XL\",],\n",
    "        \"Shape\": [\n",
    "            \"Circle\",\n",
    "            \"Square\",\n",
    "            \"Triangle\",   \n",
    "            \"Circle\",\n",
    "        ],\n",
    "        \"Temperature\": [\"Hot\", \"Cold\", \"Hot\", \"Warm\",],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8a888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
